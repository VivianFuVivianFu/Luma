# verify_model_name.py
# ä½¿ç”¨å®˜æ–¹æ–‡æ¡£æ­£ç¡®æ ¼å¼éªŒè¯ Meta Llama 3 70B æ¨¡å‹

import os
import requests
import json
from dotenv import load_dotenv

# å¼ºåˆ¶è¦†ç›–ç³»ç»Ÿç¯å¢ƒå˜é‡
load_dotenv(override=True)

def check_api_key():
    """æ£€æŸ¥ Together.ai API Key"""
    # ä¸´æ—¶ç›´æ¥ä½¿ç”¨æ­£ç¡®çš„API Key
    together_api_key = "tgp_v1_F2EI8G3enFm67hoiUQRZxJlRWGsbYt-xE7As3V0y0b4"
    
    print(f"âœ… API Key å·²æ‰¾åˆ°: {together_api_key[:10]}...")
    return together_api_key

def test_official_models(api_key):
    """æµ‹è¯•å®˜æ–¹æ–‡æ¡£ä¸­ç¡®è®¤çš„ LLaMA 3 70B æ¨¡å‹"""
    
    # æ ¹æ®å®˜æ–¹æ–‡æ¡£çš„å¯ç”¨æ¨¡å‹ç«¯ç‚¹
    official_models = [
        "meta-llama/Meta-Llama-3.3-70B-Instruct-Turbo",  # æ­£ç¢ºçš„ 70B æ¨¡å‹åç¨±
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "meta-llama/Llama-3-70b-chat-hf"
    ]
    
    # ä½¿ç”¨å®˜æ–¹æ–‡æ¡£æ¨èçš„æ­£ç¡®ç«¯ç‚¹
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    print("ğŸ§ª æµ‹è¯•å®˜æ–¹æ–‡æ¡£ä¸­çš„ LLaMA 3 70B æ¨¡å‹:")
    print("ğŸ“‹ ä½¿ç”¨æ­£ç¡®çš„ /v1/chat/completions ç«¯ç‚¹")
    print("-" * 60)
    
    working_models = []
    
    for model_name in official_models:
        print(f"\nğŸ” æµ‹è¯•: {model_name}")
        
        # ä½¿ç”¨å®˜æ–¹æ–‡æ¡£çš„æ­£ç¡® messages æ ¼å¼
        data = {
            "model": model_name,
            "messages": [
                {
                    "role": "user",
                    "content": "Hello, please respond briefly to confirm you're working."
                }
            ],
            "max_tokens": 50,
            "temperature": 0.1
        }
        
        try:
            response = requests.post(url, headers=headers, json=data, timeout=45)
            
            if response.status_code == 200:
                result = response.json()
                response_text = result["choices"][0]["message"]["content"].strip()
                print(f"   âœ… å·¥ä½œæ­£å¸¸!")
                print(f"   ğŸ“ å›ç­”: {response_text[:80]}...")
                working_models.append({
                    'name': model_name,
                    'response': response_text,
                    'status': 'working'
                })
                
            elif response.status_code == 400:
                error_info = response.json()
                error_message = error_info.get("error", {}).get("message", "Unknown error")
                print(f"   âŒ å¤±è´¥ (400): {error_message}")
                
            elif response.status_code == 401:
                print(f"   âŒ è®¤è¯å¤±è´¥ (401): è¯·æ£€æŸ¥ API Key")
                
            elif response.status_code == 404:
                print(f"   âŒ æ¨¡å‹ä¸å­˜åœ¨ (404)")
                
            else:
                print(f"   âŒ å¤±è´¥ ({response.status_code}): {response.text[:100]}...")
                
        except requests.exceptions.Timeout:
            print(f"   â° è¶…æ—¶ (æ¨¡å‹å¯èƒ½éœ€è¦æ›´é•¿åŠ è½½æ—¶é—´)")
        except Exception as e:
            print(f"   âŒ è¿æ¥å¤±è´¥: {e}")
    
    return working_models

def test_psychotherapy_capability(api_key, model_name):
    """æµ‹è¯•å¿ƒç†æ²»ç–—é—®é¢˜å›ç­”èƒ½åŠ›"""
    
    url = "https://api.together.xyz/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # ä½¿ç”¨ç³»ç»Ÿæ¶ˆæ¯è®¾ç½®è§’è‰²
    data = {
        "model": model_name,
        "messages": [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†å¥åº·åŠ©æ‰‹ã€‚è¯·æä¾›å‡†ç¡®ã€ç®€æ´çš„ä¸“ä¸šå›ç­”ã€‚"
            },
            {
                "role": "user",
                "content": "ä¸ºä»€ä¹ˆcptsdçš„äººå®¹æ˜“å¾—ç„¦è™‘å‹ä¾æ‹ï¼Ÿè¯·ç®€æ´å›ç­”ã€‚"
            }
        ],
        "max_tokens": 200,
        "temperature": 0.3
    }
    
    try:
        print(f"\nğŸ§  æµ‹è¯• {model_name} çš„å¿ƒç†æ²»ç–—é—®é¢˜å›ç­”èƒ½åŠ›...")
        response = requests.post(url, headers=headers, json=data, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            answer = result["choices"][0]["message"]["content"].strip()
            print(f"âœ… å¿ƒç†æ²»ç–—é—®é¢˜æµ‹è¯•æˆåŠŸ!")
            print(f"ğŸ“ å›ç­”é¢„è§ˆ: {answer[:150]}...")
            return True, answer
        else:
            print(f"âŒ å¿ƒç†æ²»ç–—é—®é¢˜æµ‹è¯•å¤±è´¥: {response.status_code}")
            return False, None
            
    except Exception as e:
        print(f"âŒ å¿ƒç†æ²»ç–—é—®é¢˜æµ‹è¯•å‡ºé”™: {e}")
        return False, None

def get_model_info(api_key):
    """å°è¯•è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆå¦‚æœ API æ”¯æŒï¼‰"""
    
    url = "https://api.together.xyz/v1/models"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    try:
        print("\nğŸ” å°è¯•è·å– Together.ai æ¨¡å‹åˆ—è¡¨...")
        response = requests.get(url, headers=headers, timeout=30)
        
        if response.status_code == 200:
            models_data = response.json()
            
            llama3_70b_models = []
            for model in models_data.get("data", []):
                model_name = model.get("id", "")
                if ("llama-3" in model_name.lower() or "llama3" in model_name.lower()) and "70b" in model_name.lower():
                    llama3_70b_models.append(model_name)
            
            if llama3_70b_models:
                print(f"âœ… æ‰¾åˆ° {len(llama3_70b_models)} ä¸ª LLaMA 3 70B æ¨¡å‹:")
                for model in llama3_70b_models:
                    print(f"   â€¢ {model}")
            else:
                print("âš ï¸ æœªæ‰¾åˆ° LLaMA 3 70B æ¨¡å‹")
                
            return llama3_70b_models
            
        else:
            print(f"âš ï¸ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ ({response.status_code})")
            return []
            
    except Exception as e:
        print(f"âš ï¸ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def recommend_best_model(working_models):
    """æ¨èæœ€ä½³æ¨¡å‹"""
    
    if not working_models:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹")
        return None
    
    print(f"\nğŸ¯ å¯ç”¨æ¨¡å‹æ€»ç»“ ({len(working_models)} ä¸ª):")
    print("-" * 60)
    
    # ä¼˜å…ˆçº§æ’åº
    priority_order = [
        "meta-llama/Meta-Llama-3-70B-Instruct-Turbo",
        "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
        "meta-llama/Llama-3.3-70B-Instruct-Turbo",
        "meta-llama/Llama-3-70b-chat-hf"
    ]
    
    # æŒ‰ä¼˜å…ˆçº§æ’åº
    sorted_models = []
    for priority_model in priority_order:
        for model in working_models:
            if model['name'] == priority_model:
                sorted_models.append(model)
                break
    
    # æ·»åŠ å…¶ä»–æ¨¡å‹
    for model in working_models:
        if model not in sorted_models:
            sorted_models.append(model)
    
    # æ˜¾ç¤ºç»“æœ
    best_model = None
    for i, model in enumerate(sorted_models):
        if i == 0:
            print(f"ğŸŒŸ æ¨è: {model['name']}")
            best_model = model['name']
        else:
            print(f"âœ… å¯ç”¨: {model['name']}")
    
    return best_model

def main():
    print("ğŸ” Together.ai Meta Llama 3 70B æ¨¡å‹éªŒè¯å·¥å…·")
    print("ğŸ“‹ ä½¿ç”¨å®˜æ–¹æ–‡æ¡£æ¨èçš„æ­£ç¡® API æ ¼å¼")
    print("="*60)
    
    # æ£€æŸ¥ API Key
    api_key = check_api_key()
    if not api_key:
        return
    
    # æµ‹è¯•å®˜æ–¹æ¨¡å‹
    working_models = test_official_models(api_key)
    
    # æ¨èæœ€ä½³æ¨¡å‹
    best_model = recommend_best_model(working_models)
    
    # å¦‚æœæ‰¾åˆ°æ¨èæ¨¡å‹ï¼Œæµ‹è¯•å¿ƒç†æ²»ç–—èƒ½åŠ›
    if best_model:
        therapy_success, therapy_answer = test_psychotherapy_capability(api_key, best_model)
        
        if therapy_success:
            print(f"\nğŸ‰ å®Œæ•´æµ‹è¯•é€šè¿‡!")
            print(f"âœ… æ¨èæ¨¡å‹: {best_model}")
            print(f"âœ… API ç«¯ç‚¹: /v1/chat/completions")
            print(f"âœ… è¯·æ±‚æ ¼å¼: messages æ•°ç»„")
            print(f"âœ… å¿ƒç†æ²»ç–—é—®é¢˜: å¯ä»¥æ­£å¸¸å›ç­”")
            
            print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            print(f"   1. è¿è¡Œ update_model_names.py æ›´æ–°æ‰€æœ‰æ–‡ä»¶")
            print(f"   2. ç¡®ä¿ä½¿ç”¨ /v1/chat/completions ç«¯ç‚¹")
            print(f"   3. ç¡®ä¿ä½¿ç”¨ messages æ ¼å¼ï¼ˆä¸æ˜¯ promptï¼‰")
    
    # å°è¯•è·å–å®Œæ•´æ¨¡å‹åˆ—è¡¨
    get_model_info(api_key)
    
    # æœ€ç»ˆæ€»ç»“
    print(f"\nğŸ“‹ éªŒè¯ç»“æœæ€»ç»“")
    print("="*60)
    if working_models:
        print(f"ğŸ‰ éªŒè¯æˆåŠŸ!")
        print(f"âœ… æ‰¾åˆ° {len(working_models)} ä¸ªå¯ç”¨çš„ LLaMA 3 70B æ¨¡å‹")
        print(f"ğŸŒŸ æ¨èä½¿ç”¨: {best_model}")
    else:
        print(f"âŒ éªŒè¯å¤±è´¥ï¼Œæ²¡æœ‰æ‰¾åˆ°å¯ç”¨æ¨¡å‹")
        print(f"ğŸ’¡ è¯·æ£€æŸ¥:")
        print(f"   1. TOGETHER_API_KEY æ˜¯å¦æ­£ç¡®")
        print(f"   2. Together.ai è´¦æˆ·æ˜¯å¦æœ‰ä½™é¢")
        print(f"   3. æ˜¯å¦æœ‰è®¿é—® 70B æ¨¡å‹çš„æƒé™")

if __name__ == "__main__":
    main()
    
