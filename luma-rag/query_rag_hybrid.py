# query_rag_hybrid.py
# æ··åˆæ£€ç´¢ç­–ç•¥ - ä¸­è‹±æ–‡å…³é”®è¯åŒæ—¶æ£€ç´¢

import os
import time
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import dotenv
import re

dotenv.load_dotenv()

VECTOR_DB_PATH = "vector_store"

def detect_language(text):
    """æ£€æµ‹æ–‡æœ¬è¯­è¨€"""
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    total_chars = len(text.strip())
    return "zh" if total_chars > 0 and chinese_chars / total_chars > 0.3 else "en"

def extract_keywords_bilingual(question):
    """æå–ä¸­è‹±æ–‡å…³é”®è¯"""
    # å¿ƒç†å­¦ä¸“ä¸šæœ¯è¯­å¯¹ç…§è¡¨
    psychology_terms = {
        "ä¾æ‹": "attachment",
        "ç„¦è™‘": "anxiety anxious",
        "åˆ›ä¼¤": "trauma PTSD CPTSD",
        "æŠ‘éƒ": "depression depressive",
        "æ²»ç–—": "therapy treatment",
        "å…³ç³»": "relationship",
        "æƒ…ç»ª": "emotion emotional",
        "å¿ƒç†": "psychology psychological",
        "è¾¹ç•Œ": "boundary boundaries",
        "å…±ä¾å­˜": "codependency codependent",
        "ä¾èµ–": "dependency dependent",
        "å›é¿": "avoidant avoidance",
        "å®‰å…¨": "secure security",
        "ææƒ§": "fear afraid",
        "æ„¤æ€’": "anger angry",
        "ç¾è€»": "shame",
        "å†…ç–š": "guilt",
        "è‡ªå°Š": "self-esteem",
        "è‡ªä¿¡": "confidence",
        "å†¥æƒ³": "meditation mindfulness",
        "æ­£å¿µ": "mindfulness",
        "è®¤çŸ¥": "cognitive",
        "è¡Œä¸º": "behavior behavioral",
        "DBT": "DBT dialectical",
        "CBT": "CBT cognitive behavioral",
        "EMDR": "EMDR",
        "IFS": "IFS internal family",
        "åˆ›ä¼¤å": "post-traumatic",
        "å¤æ‚åˆ›ä¼¤": "complex trauma CPTSD",
        "è§£ç¦»": "dissociation dissociative",
        "è§¦å‘": "trigger triggered",
        "é—ªå›": "flashback",
        "å™©æ¢¦": "nightmare",
        "è¿‡åº¦è­¦è§‰": "hypervigilance",
        "å›é¿ç—‡çŠ¶": "avoidance symptoms",
        "éº»æœ¨": "numbness numb",
        "åˆ†ç¦»": "detachment",
        "äººé™…å…³ç³»": "interpersonal relationship",
        "äº²å¯†å…³ç³»": "intimate relationship",
        "æ²Ÿé€š": "communication",
        "å†²çª": "conflict",
        "è¾¹ç•Œè®¾å®š": "boundary setting",
        "æƒ…æ„Ÿè°ƒèŠ‚": "emotional regulation",
        "åº”å¯¹": "coping",
        "åº·å¤": "recovery healing",
        "æ²»æ„ˆ": "healing",
        "æˆé•¿": "growth",
        "éŸ§æ€§": "resilience"
    }
    
    user_language = detect_language(question)
    keywords = []
    
    if user_language == "zh":
        # ä¸­æ–‡é—®é¢˜ï¼Œæ·»åŠ å¯¹åº”çš„è‹±æ–‡å…³é”®è¯
        for zh_term, en_terms in psychology_terms.items():
            if zh_term in question:
                keywords.extend(en_terms.split())
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸“ä¸šæœ¯è¯­ï¼Œä½¿ç”¨ç®€å•ç¿»è¯‘
        if not keywords:
            # æå–ä¸­æ–‡å…³é”®è¯å¹¶æ·»åŠ å¸¸è§è‹±æ–‡åŒä¹‰è¯
            question_lower = question.lower()
            if "ä»€ä¹ˆ" in question or "ä»‹ç»" in question:
                keywords.append("definition concept")
            if "å¦‚ä½•" in question or "æ€ä¹ˆ" in question:
                keywords.append("how to method")
            if "ä¸ºä»€ä¹ˆ" in question:
                keywords.append("why reason cause")
            if "ç—‡çŠ¶" in question:
                keywords.append("symptoms signs")
            if "åŸå› " in question:
                keywords.append("causes reasons")
            if "å½±å“" in question:
                keywords.append("effects impact")
    
    return " ".join(keywords) if keywords else question

def create_hybrid_retriever(db, question):
    """åˆ›å»ºæ··åˆæ£€ç´¢å™¨"""
    user_language = detect_language(question)
    
    if user_language == "zh":
        # å¯¹ä¸­æ–‡é—®é¢˜ä½¿ç”¨æ··åˆæ£€ç´¢ç­–ç•¥
        english_keywords = extract_keywords_bilingual(question)
        
        # ä½¿ç”¨è‹±æ–‡å…³é”®è¯æ£€ç´¢
        if english_keywords and english_keywords != question:
            print(f"ğŸ” ä½¿ç”¨å…³é”®è¯æ£€ç´¢: {english_keywords}")
            docs1 = db.similarity_search(english_keywords, k=3)
        else:
            docs1 = []
        
        # åŒæ—¶ä½¿ç”¨åŸé—®é¢˜æ£€ç´¢
        docs2 = db.similarity_search(question, k=2)
        
        # åˆå¹¶å»é‡
        all_docs = docs1 + docs2
        unique_docs = []
        seen_content = set()
        
        for doc in all_docs:
            content_hash = hash(doc.page_content[:100])
            if content_hash not in seen_content:
                unique_docs.append(doc)
                seen_content.add(content_hash)
        
        return unique_docs[:5]
    else:
        # è‹±æ–‡é—®é¢˜ç›´æ¥æ£€ç´¢
        return db.similarity_search(question, k=5)

def load_vectorstore():
    """åŠ è½½å·²æ„å»ºçš„å‘é‡æ•°æ®åº“"""
    embeddings = OpenAIEmbeddings()
    db = FAISS.load_local(VECTOR_DB_PATH, embeddings, allow_dangerous_deserialization=True)
    return db

def ask_question_hybrid(db, question):
    """ä½¿ç”¨æ··åˆæ£€ç´¢ç­–ç•¥çš„é—®ç­”"""
    start_time = time.time()
    
    user_language = detect_language(question)
    print(f"\nğŸŒ æ£€æµ‹è¯­è¨€: {'ä¸­æ–‡' if user_language == 'zh' else 'è‹±æ–‡'}")
    
    # æ··åˆæ£€ç´¢
    retrieval_start = time.time()
    relevant_docs = create_hybrid_retriever(db, question)
    retrieval_end = time.time()
    print(f"ğŸ” æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£å—")
    print(f"â±ï¸ æ£€ç´¢è€—æ—¶: {retrieval_end - retrieval_start:.2f}ç§’")
    
    # æ„å»ºä¸Šä¸‹æ–‡
    context = "\n\n".join([doc.page_content for doc in relevant_docs])
    
    # åˆ›å»ºæ™ºèƒ½æç¤ºæ¨¡æ¿
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7)
    
    if user_language == "zh":
        prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„å¿ƒç†å¥åº·åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹è‹±æ–‡æ–‡æ¡£å†…å®¹ï¼Œç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
å¦‚æœæ–‡æ¡£ä¿¡æ¯ä¸è¶³ï¼Œè¯·è¯šå®è¯´æ˜ã€‚è¯·æä¾›å‡†ç¡®ã€ä¸“ä¸šä¸”æ˜“æ‡‚çš„å›ç­”ã€‚

ç›¸å…³æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š"""
    else:
        prompt = f"""
You are a professional mental health assistant. Answer the question based on the document content.
If information is insufficient, state that clearly. Provide accurate and professional answers.

Relevant document content:
{context}

Question: {question}

Answer:"""
    
    # ç”Ÿæˆç­”æ¡ˆ
    generation_start = time.time()
    response = llm.invoke(prompt)
    answer = response.content.strip()
    generation_end = time.time()
    print(f"â±ï¸ ç”Ÿæˆç­”æ¡ˆè€—æ—¶: {generation_end - generation_start:.2f}ç§’")
    
    print(f"\nğŸ¤– å›ç­”ï¼š")
    print(answer)
    
    print(f"\nğŸ“š ç›¸å…³æ–‡æ¡£æ¥æºï¼š")
    for i, doc in enumerate(relevant_docs, 1):
        source = doc.metadata.get("source", "æœªçŸ¥æ¥æº")
        print(f"  {i}. {os.path.basename(source)}")
    
    end_time = time.time()
    total_time = end_time - start_time
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
    
    return answer, relevant_docs

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ­£åœ¨åŠ è½½æ··åˆæ£€ç´¢ RAG ç³»ç»Ÿ...")
    
    try:
        db = load_vectorstore()
        print("âœ… å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸï¼")
        print("ğŸš€ ç‰¹æ€§ï¼šæ··åˆæ£€ç´¢ã€æ— ç¿»è¯‘å»¶è¿Ÿã€æ™ºèƒ½å…³é”®è¯æ˜ å°„")
        
        print("\n" + "="*60)
        print("ğŸ§  å¿ƒç†å¥åº·æ··åˆæ£€ç´¢ RAG é—®ç­”ç³»ç»Ÿ")
        print("ğŸ’¬ æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡æé—®ï¼ˆè¶…ä½å»¶è¿Ÿï¼‰")
        print("è¾“å…¥ 'quit' æˆ– 'exit' æˆ– 'é€€å‡º' ç»“æŸ")
        print("="*60)
        
        while True:
            question = input("\nâ“ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
            
            if question.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break
                
            if not question:
                print("è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜ã€‚")
                continue
            
            try:
                ask_question_hybrid(db, question)
            except Exception as e:
                print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
